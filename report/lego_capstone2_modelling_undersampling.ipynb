{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b0239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1cb0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=1000\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bb3979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b9d4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set_num</th>\n",
       "      <th>set_name</th>\n",
       "      <th>year</th>\n",
       "      <th>theme_id</th>\n",
       "      <th>num_parts</th>\n",
       "      <th>set_num_len</th>\n",
       "      <th>set_name_len</th>\n",
       "      <th>theme_name</th>\n",
       "      <th>id</th>\n",
       "      <th>part_num</th>\n",
       "      <th>color_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>color_name</th>\n",
       "      <th>part_name</th>\n",
       "      <th>is_trans</th>\n",
       "      <th>theme_name_len</th>\n",
       "      <th>part_num_len</th>\n",
       "      <th>color_name_len</th>\n",
       "      <th>part_name_len</th>\n",
       "      <th>is_ninjago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-1</td>\n",
       "      <td>Gears</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Technic</td>\n",
       "      <td>24696</td>\n",
       "      <td>132a</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Light Gray</td>\n",
       "      <td>Tyre Smooth Old Style - Small</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-1</td>\n",
       "      <td>Gears</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Technic</td>\n",
       "      <td>24696</td>\n",
       "      <td>3020</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>Plate 2 x 4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-1</td>\n",
       "      <td>Gears</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Technic</td>\n",
       "      <td>24696</td>\n",
       "      <td>3062c</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>Brick Round 1 x 1 Solid Stud, No Bottom Groove</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-1</td>\n",
       "      <td>Gears</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Technic</td>\n",
       "      <td>24696</td>\n",
       "      <td>3404bc01</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>White</td>\n",
       "      <td>Turntable 4 x 4 - Old Type Complete, Perfectly...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-1</td>\n",
       "      <td>Gears</td>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Technic</td>\n",
       "      <td>24696</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Light Gray</td>\n",
       "      <td>Tyre Smooth Old Style - Large</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  set_num set_name  year  theme_id  num_parts  set_num_len  set_name_len  \\\n",
       "0   001-1    Gears  1965         1         43            5             5   \n",
       "1   001-1    Gears  1965         1         43            5             5   \n",
       "2   001-1    Gears  1965         1         43            5             5   \n",
       "3   001-1    Gears  1965         1         43            5             5   \n",
       "4   001-1    Gears  1965         1         43            5             5   \n",
       "\n",
       "  theme_name     id  part_num  color_id  quantity  color_name  \\\n",
       "0    Technic  24696      132a         7         4  Light Gray   \n",
       "1    Technic  24696      3020        15         4       White   \n",
       "2    Technic  24696     3062c        15         1       White   \n",
       "3    Technic  24696  3404bc01        15         4       White   \n",
       "4    Technic  24696        36         7         4  Light Gray   \n",
       "\n",
       "                                           part_name  is_trans  \\\n",
       "0                      Tyre Smooth Old Style - Small         0   \n",
       "1                                        Plate 2 x 4         0   \n",
       "2     Brick Round 1 x 1 Solid Stud, No Bottom Groove         0   \n",
       "3  Turntable 4 x 4 - Old Type Complete, Perfectly...         0   \n",
       "4                      Tyre Smooth Old Style - Large         0   \n",
       "\n",
       "   theme_name_len  part_num_len  color_name_len  part_name_len  is_ninjago  \n",
       "0               7             4              10             29           0  \n",
       "1               7             4               5             11           0  \n",
       "2               7             5               5             46           0  \n",
       "3               7             8               5             52           0  \n",
       "4               7             2              10             29           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db7da0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(919288, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad27a2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['set_num', 'set_name', 'year', 'theme_id', 'num_parts', 'set_num_len',\n",
       "       'set_name_len', 'theme_name', 'id', 'part_num', 'color_id', 'quantity',\n",
       "       'color_name', 'part_name', 'is_trans', 'theme_name_len', 'part_num_len',\n",
       "       'color_name_len', 'part_name_len', 'is_ninjago'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf72b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set_num',\n",
       " 'set_name',\n",
       " 'theme_id',\n",
       " 'theme_name',\n",
       " 'id',\n",
       " 'part_num',\n",
       " 'color_name',\n",
       " 'part_name',\n",
       " 'theme_name_len',\n",
       " 'is_ninjago']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = 'set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd8571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b06c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_under = list()\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn_under.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cbfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[fn_under]\n",
    "y = df['is_ninjago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d38790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e056dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([pd.DataFrame(X_train, columns=fn_under), pd.DataFrame(y_train, columns=['is_ninjago'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([pd.DataFrame(X_test, columns=fn_under), pd.DataFrame(y_test, columns=['is_ninjago'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b7c03ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(827359, 11)\n",
      "(91929, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3eebd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>num_parts</th>\n",
       "      <th>set_num_len</th>\n",
       "      <th>set_name_len</th>\n",
       "      <th>color_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>is_trans</th>\n",
       "      <th>part_num_len</th>\n",
       "      <th>color_name_len</th>\n",
       "      <th>part_name_len</th>\n",
       "      <th>is_ninjago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>774631</th>\n",
       "      <td>2014</td>\n",
       "      <td>368</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417226</th>\n",
       "      <td>2013</td>\n",
       "      <td>284</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414960</th>\n",
       "      <td>2010</td>\n",
       "      <td>631</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896798</th>\n",
       "      <td>2008</td>\n",
       "      <td>842</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591153</th>\n",
       "      <td>2007</td>\n",
       "      <td>974</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555268</th>\n",
       "      <td>2016</td>\n",
       "      <td>754</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575778</th>\n",
       "      <td>2015</td>\n",
       "      <td>361</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576490</th>\n",
       "      <td>2015</td>\n",
       "      <td>2030</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612760</th>\n",
       "      <td>2020</td>\n",
       "      <td>1017</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567503</th>\n",
       "      <td>2019</td>\n",
       "      <td>364</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  num_parts  set_num_len  set_name_len  color_id  quantity  \\\n",
       "774631  2014        368            7            19        15         1   \n",
       "417226  2013        284            7            16         0         1   \n",
       "414960  2010        631            6            20         0         1   \n",
       "896798  2008        842            6            33         0         2   \n",
       "591153  2007        974            6            19        70         3   \n",
       "555268  2016        754            7            17         2         3   \n",
       "575778  2015        361            7            15        19         1   \n",
       "576490  2015       2030            7            18         0         1   \n",
       "612760  2020       1017            7            23        27         8   \n",
       "567503  2019        364            7            11         0         2   \n",
       "\n",
       "        is_trans  part_num_len  color_name_len  part_name_len  is_ninjago  \n",
       "774631         0            11               5             59           0  \n",
       "417226         0             5               5             45           0  \n",
       "414960         0             5               5             57           0  \n",
       "896798         0             4               5             12           0  \n",
       "591153         0             6              13             53           0  \n",
       "555268         0             4               5             11           1  \n",
       "575778         0             5               3             27           1  \n",
       "576490         0             6               5             54           1  \n",
       "612760         0             4               4             33           1  \n",
       "567503         0             5               5             43           1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_train = df_train.groupby('is_ninjago')\n",
    "\n",
    "df_grouped_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28525939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_ninjago\n",
      "0    795565\n",
      "1     31794\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_grouped_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b34ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[795565, 31794]\n"
     ]
    }
   ],
   "source": [
    "list(df_grouped_train)[0][1]\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for is_ninjago, group in df_grouped_train:\n",
    "    lengths.append(group.shape[0])\n",
    "    \n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b418aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[        year  num_parts  set_num_len  set_name_len  color_id  quantity  \\\n",
       " 732356  2021        590            7            29        72         4   \n",
       " 778246  2007        604            6            12       191         1   \n",
       " 126987  2021       2164            7            19        10         6   \n",
       " 245728  2015        334            7            20        31         2   \n",
       " 45835   2021       2355            7            28         1         4   \n",
       " ...      ...        ...          ...           ...       ...       ...   \n",
       " 53604   1985        785            6            54         1         2   \n",
       " 269801  2017        326            7            25       322         4   \n",
       " 227251  2020        134            7            10       320         2   \n",
       " 878418  1991        900            6             9         4        14   \n",
       " 523567  1992        406            6            17        34         2   \n",
       " \n",
       "         is_trans  part_num_len  color_name_len  part_name_len  is_ninjago  \n",
       " 732356         0             4              16             11           0  \n",
       " 778246         0             5              19             39           0  \n",
       " 126987         0             5              12             22           0  \n",
       " 245728         0             5               8             22           0  \n",
       " 45835          0             4               4             28           0  \n",
       " ...          ...           ...             ...            ...         ...  \n",
       " 53604          0             4               4             16           0  \n",
       " 269801         0             5              12             56           0  \n",
       " 227251         0             5               8             24           0  \n",
       " 878418         0             4               3             11           0  \n",
       " 523567         1             4              11             32           0  \n",
       " \n",
       " [31794 rows x 11 columns],\n",
       "         year  num_parts  set_num_len  set_name_len  color_id  quantity  \\\n",
       " 563263  2018        497            7            12        72         1   \n",
       " 610323  2020        226            7            14         0         2   \n",
       " 566008  2019        154            7            16         0         2   \n",
       " 577027  2015        188            7            13       179         2   \n",
       " 619186  2021        737            7            12        72         2   \n",
       " ...      ...        ...          ...           ...       ...       ...   \n",
       " 574708  2015       1264            7            32       272         7   \n",
       " 568300  2019       1189            7            11         0         7   \n",
       " 617412  2021       5709            7            20         0         5   \n",
       " 883999  2012        255            6            13        27         1   \n",
       " 572218  2014        253            7            11        72         2   \n",
       " \n",
       "         is_trans  part_num_len  color_name_len  part_name_len  is_ninjago  \n",
       " 563263         0             5              16             13           1  \n",
       " 610323         0             5               5             63           1  \n",
       " 566008         0             5               5             45           1  \n",
       " 577027         0             5              11             60           1  \n",
       " 619186         0             5              16             29           1  \n",
       " ...          ...           ...             ...            ...         ...  \n",
       " 574708         0             5               9             75           1  \n",
       " 568300         0             5               5             22           1  \n",
       " 617412         0             5               5             60           1  \n",
       " 883999         0             4               4             11           1  \n",
       " 572218         0             5              16             56           1  \n",
       " \n",
       " [31794 rows x 11 columns]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_train = list()\n",
    "\n",
    "for is_ninjago, group in df_grouped_train:\n",
    "    dfs_train.append(group.sample(min(lengths)))\n",
    "    \n",
    "dfs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dac9a7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>num_parts</th>\n",
       "      <th>set_num_len</th>\n",
       "      <th>set_name_len</th>\n",
       "      <th>color_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>is_trans</th>\n",
       "      <th>part_num_len</th>\n",
       "      <th>color_name_len</th>\n",
       "      <th>part_name_len</th>\n",
       "      <th>is_ninjago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>732356</th>\n",
       "      <td>2021</td>\n",
       "      <td>590</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778246</th>\n",
       "      <td>2007</td>\n",
       "      <td>604</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126987</th>\n",
       "      <td>2021</td>\n",
       "      <td>2164</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245728</th>\n",
       "      <td>2015</td>\n",
       "      <td>334</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45835</th>\n",
       "      <td>2021</td>\n",
       "      <td>2355</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  num_parts  set_num_len  set_name_len  color_id  quantity  \\\n",
       "732356  2021        590            7            29        72         4   \n",
       "778246  2007        604            6            12       191         1   \n",
       "126987  2021       2164            7            19        10         6   \n",
       "245728  2015        334            7            20        31         2   \n",
       "45835   2021       2355            7            28         1         4   \n",
       "\n",
       "        is_trans  part_num_len  color_name_len  part_name_len  is_ninjago  \n",
       "732356         0             4              16             11           0  \n",
       "778246         0             5              19             39           0  \n",
       "126987         0             5              12             22           0  \n",
       "245728         0             5               8             22           0  \n",
       "45835          0             4               4             28           0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balancedbyunder = pd.concat(dfs_train)\n",
    "df_balancedbyunder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ace6f1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63588, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balancedbyunder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c04c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:02<00:01,  2.48it/s]C:\\Users\\marki\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:03<00:00,  2.00it/s]C:\\Users\\marki\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "11it [00:04,  2.60it/s]                                                                                                \n"
     ]
    }
   ],
   "source": [
    "hyper_table_df_grouped = list()\n",
    "fn_under = list()\n",
    "\n",
    "for i, name in tqdm(enumerate(df_balancedbyunder.columns), total=len(df_balancedbyunder.columns)-1):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn_under.append(name)\n",
    "    model.fit(df_balancedbyunder[fn_under], df_balancedbyunder['is_ninjago'])\n",
    "    \n",
    "    s_train = model.score(df_balancedbyunder[fn_under], df_balancedbyunder['is_ninjago'])\n",
    "    s_test = model.score(df_test[fn_under], df_test['is_ninjago'])\n",
    "    y_pred = model.predict(df_test[fn_under])\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "    precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "    recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "    accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "    f1 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "    hyper_table_df_grouped.append(dict(sample='under', \n",
    "                        missing_feature=target_names[0], \n",
    "                        train_score=s_train, \n",
    "                        test_score=s_test,\n",
    "                        precision=precision,\n",
    "                        recall=recall,\n",
    "                        accuracy=accuracy,\n",
    "                        f1_score=f1,\n",
    "                        model=model, \n",
    "                        num_features=df[fn_under].shape[1], \n",
    "                        num_rows_train=df_balancedbyunder.shape[0], \n",
    "                        num_rows_test=df_test.shape[0],\n",
    "                        last_feature=fn_under[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f85c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aea2ee45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:20,  1.87s/it]                                                                                                \n"
     ]
    }
   ],
   "source": [
    "fn_under = list()\n",
    "for i, name in tqdm(enumerate(df_balancedbyunder.columns), total=len(df_balancedbyunder.columns)-1):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn_under.append(name)\n",
    "    model_rf.fit(df_balancedbyunder[fn_under], df_balancedbyunder['is_ninjago'])\n",
    "    \n",
    "    s_train = model_rf.score(df_balancedbyunder[fn_under], df_balancedbyunder['is_ninjago'])\n",
    "    s_test = model_rf.score(df_test[fn_under], df_test['is_ninjago'])\n",
    "    y_pred = model_rf.predict(df_test[fn_under])\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "    precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "    recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "    accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "    f1 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "    hyper_table_df_grouped.append(dict(sample='under', \n",
    "                        missing_feature=target_names[0], \n",
    "                        train_score=s_train, \n",
    "                        test_score=s_test,\n",
    "                        precision=precision,\n",
    "                        recall=recall,\n",
    "                        accuracy=accuracy,\n",
    "                        f1_score=f1,\n",
    "                        model=model_rf, \n",
    "                        num_features=df[fn_under].shape[1], \n",
    "                        num_rows_train=df_balancedbyunder.shape[0], \n",
    "                        num_rows_test=df_test.shape[0], \n",
    "                        last_feature=fn_under[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9922449e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>missing_feature</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows_train</th>\n",
       "      <th>num_rows_test</th>\n",
       "      <th>last_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.999654</td>\n",
       "      <td>0.997552</td>\n",
       "      <td>0.942747</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.997552</td>\n",
       "      <td>0.970273</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>4</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.991929</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.997550</td>\n",
       "      <td>0.991929</td>\n",
       "      <td>0.908077</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>5</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.994732</td>\n",
       "      <td>0.988241</td>\n",
       "      <td>0.772890</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.988241</td>\n",
       "      <td>0.871691</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>3</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.991759</td>\n",
       "      <td>0.982845</td>\n",
       "      <td>0.700057</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.982845</td>\n",
       "      <td>0.823107</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>2</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.982595</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.996189</td>\n",
       "      <td>0.982595</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>6</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.973371</td>\n",
       "      <td>0.600856</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>0.973371</td>\n",
       "      <td>0.748975</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>7</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.969879</td>\n",
       "      <td>0.570736</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>0.969879</td>\n",
       "      <td>0.725052</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.955672</td>\n",
       "      <td>0.473883</td>\n",
       "      <td>0.990201</td>\n",
       "      <td>0.955672</td>\n",
       "      <td>0.641001</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>8</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954704</td>\n",
       "      <td>0.468477</td>\n",
       "      <td>0.991018</td>\n",
       "      <td>0.954704</td>\n",
       "      <td>0.636205</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>10</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.546329</td>\n",
       "      <td>0.739310</td>\n",
       "      <td>0.056403</td>\n",
       "      <td>0.351116</td>\n",
       "      <td>0.739310</td>\n",
       "      <td>0.097193</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>2</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.619299</td>\n",
       "      <td>0.654114</td>\n",
       "      <td>0.066418</td>\n",
       "      <td>0.586282</td>\n",
       "      <td>0.654114</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>3</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.620306</td>\n",
       "      <td>0.642703</td>\n",
       "      <td>0.064961</td>\n",
       "      <td>0.592814</td>\n",
       "      <td>0.642703</td>\n",
       "      <td>0.117090</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>5</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.631346</td>\n",
       "      <td>0.640603</td>\n",
       "      <td>0.066824</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.640603</td>\n",
       "      <td>0.120578</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>7</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.631141</td>\n",
       "      <td>0.640440</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.640440</td>\n",
       "      <td>0.120530</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>6</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.639102</td>\n",
       "      <td>0.066069</td>\n",
       "      <td>0.611323</td>\n",
       "      <td>0.639102</td>\n",
       "      <td>0.119249</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>4</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.631204</td>\n",
       "      <td>0.637764</td>\n",
       "      <td>0.066237</td>\n",
       "      <td>0.615678</td>\n",
       "      <td>0.637764</td>\n",
       "      <td>0.119607</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>8</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.617302</td>\n",
       "      <td>0.627517</td>\n",
       "      <td>0.063165</td>\n",
       "      <td>0.601524</td>\n",
       "      <td>0.627517</td>\n",
       "      <td>0.114324</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.601497</td>\n",
       "      <td>0.616585</td>\n",
       "      <td>0.060473</td>\n",
       "      <td>0.591181</td>\n",
       "      <td>0.616585</td>\n",
       "      <td>0.109722</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>10</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.732025</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>0.945291</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>0.139610</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>1</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample missing_feature  train_score  test_score  precision    recall  \\\n",
       "13  under         set_num     0.999654    0.997552   0.942747  0.999456   \n",
       "14  under         set_num     0.999906    0.991929   0.833333  0.997550   \n",
       "12  under         set_num     0.994732    0.988241   0.772890  0.999456   \n",
       "11  under         set_num     0.991759    0.982845   0.700057  0.998639   \n",
       "15  under         set_num     0.999953    0.982595   0.697674  0.996189   \n",
       "16  under         set_num     0.999953    0.973371   0.600856  0.994012   \n",
       "18  under         set_num     0.999969    0.969879   0.570736  0.993740   \n",
       "17  under         set_num     0.999969    0.955672   0.473883  0.990201   \n",
       "19  under         set_num     1.000000    0.954704   0.468477  0.991018   \n",
       "1   under         set_num     0.546329    0.739310   0.056403  0.351116   \n",
       "2   under         set_num     0.619299    0.654114   0.066418  0.586282   \n",
       "4   under         set_num     0.620306    0.642703   0.064961  0.592814   \n",
       "6   under         set_num     0.631346    0.640603   0.066824  0.616494   \n",
       "5   under         set_num     0.631141    0.640440   0.066794  0.616494   \n",
       "3   under         set_num     0.626235    0.639102   0.066069  0.611323   \n",
       "7   under         set_num     0.631204    0.637764   0.066237  0.615678   \n",
       "8   under         set_num     0.617302    0.627517   0.063165  0.601524   \n",
       "9   under         set_num     0.601497    0.616585   0.060473  0.591181   \n",
       "10  under         set_num     0.732025    0.534347   0.075371  0.945291   \n",
       "0   under         set_num     0.500000    0.039966   0.039966  1.000000   \n",
       "\n",
       "    accuracy  f1_score                                              model  \\\n",
       "13  0.997552  0.970273  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "14  0.991929  0.908077  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "12  0.988241  0.871691  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "11  0.982845  0.823107  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "15  0.982595  0.820628  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "16  0.973371  0.748975  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "18  0.969879  0.725052  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "17  0.955672  0.641001  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "19  0.954704  0.636205  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "1   0.739310  0.097193                               LogisticRegression()   \n",
       "2   0.654114  0.119319                               LogisticRegression()   \n",
       "4   0.642703  0.117090                               LogisticRegression()   \n",
       "6   0.640603  0.120578                               LogisticRegression()   \n",
       "5   0.640440  0.120530                               LogisticRegression()   \n",
       "3   0.639102  0.119249                               LogisticRegression()   \n",
       "7   0.637764  0.119607                               LogisticRegression()   \n",
       "8   0.627517  0.114324                               LogisticRegression()   \n",
       "9   0.616585  0.109722                               LogisticRegression()   \n",
       "10  0.534347  0.139610  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "0   0.039966  0.076860                               LogisticRegression()   \n",
       "\n",
       "    num_features  num_rows_train  num_rows_test    last_feature  \n",
       "13             4           63588          91929    set_name_len  \n",
       "14             5           63588          91929        color_id  \n",
       "12             3           63588          91929     set_num_len  \n",
       "11             2           63588          91929       num_parts  \n",
       "15             6           63588          91929        quantity  \n",
       "16             7           63588          91929        is_trans  \n",
       "18             9           63588          91929  color_name_len  \n",
       "17             8           63588          91929    part_num_len  \n",
       "19            10           63588          91929   part_name_len  \n",
       "1              2           63588          91929       num_parts  \n",
       "2              3           63588          91929     set_num_len  \n",
       "4              5           63588          91929        color_id  \n",
       "6              7           63588          91929        is_trans  \n",
       "5              6           63588          91929        quantity  \n",
       "3              4           63588          91929    set_name_len  \n",
       "7              8           63588          91929    part_num_len  \n",
       "8              9           63588          91929  color_name_len  \n",
       "9             10           63588          91929   part_name_len  \n",
       "10             1           63588          91929            year  \n",
       "0              1           63588          91929            year  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_dfg_under = pd.DataFrame(hyper_table_df_grouped).sort_values('test_score', ascending=False)\n",
    "ht_dfg_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "007b7ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = model_rf.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())[:30]\n",
    "sorted_idx = np.argsort(feature_importance)[:30]\n",
    "\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "print(pos.size)\n",
    "sorted_idx.size\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.barh(pos, feature_importance[sorted_idx], color='orange', edgecolor='black', align='center')\n",
    "plt.yticks(pos, df_balancedbyunder[fn_under].columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance', fontsize=30)\n",
    "plt.title('Variable Importance - under sampled set', fontsize=30)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "454e7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht0 = pd.read_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/ht0.csv')\n",
    "ht_dfg_over = pd.read_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/ht_dfg_over.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe15e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_table = pd.concat([ht0, ht_dfg_over, ht_dfg_under])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "283a4b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>desc</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>model</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows_train</th>\n",
       "      <th>num_rows_test</th>\n",
       "      <th>last_feature</th>\n",
       "      <th>missing_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999401</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.992639</td>\n",
       "      <td>0.991018</td>\n",
       "      <td>0.999347</td>\n",
       "      <td>0.991828</td>\n",
       "      <td>4</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.993687</td>\n",
       "      <td>0.985302</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.989477</td>\n",
       "      <td>5</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.999064</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.977636</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.999064</td>\n",
       "      <td>0.988425</td>\n",
       "      <td>4</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999791</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.985350</td>\n",
       "      <td>0.988568</td>\n",
       "      <td>0.998956</td>\n",
       "      <td>0.986957</td>\n",
       "      <td>5</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.986791</td>\n",
       "      <td>0.976048</td>\n",
       "      <td>0.998521</td>\n",
       "      <td>0.981390</td>\n",
       "      <td>6</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.992997</td>\n",
       "      <td>0.964888</td>\n",
       "      <td>0.998325</td>\n",
       "      <td>0.978741</td>\n",
       "      <td>6</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.997944</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.984431</td>\n",
       "      <td>0.963800</td>\n",
       "      <td>0.997944</td>\n",
       "      <td>0.974006</td>\n",
       "      <td>7</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999654</td>\n",
       "      <td>0.997552</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.942747</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.997552</td>\n",
       "      <td>0.970273</td>\n",
       "      <td>4</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.997520</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.993414</td>\n",
       "      <td>0.944203</td>\n",
       "      <td>0.997520</td>\n",
       "      <td>0.968183</td>\n",
       "      <td>7</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.997378</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.981757</td>\n",
       "      <td>0.952096</td>\n",
       "      <td>0.997378</td>\n",
       "      <td>0.966699</td>\n",
       "      <td>9</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.990435</td>\n",
       "      <td>0.930049</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.959293</td>\n",
       "      <td>9</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.996367</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.985748</td>\n",
       "      <td>0.922428</td>\n",
       "      <td>0.996367</td>\n",
       "      <td>0.953037</td>\n",
       "      <td>10</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.971755</td>\n",
       "      <td>0.927055</td>\n",
       "      <td>0.996008</td>\n",
       "      <td>0.948879</td>\n",
       "      <td>8</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.987338</td>\n",
       "      <td>0.891399</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.936919</td>\n",
       "      <td>8</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.994424</td>\n",
       "      <td>0.873707</td>\n",
       "      <td>0.994757</td>\n",
       "      <td>0.930165</td>\n",
       "      <td>10</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len']</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>0.994082</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.951790</td>\n",
       "      <td>0.897387</td>\n",
       "      <td>0.994082</td>\n",
       "      <td>0.923788</td>\n",
       "      <td>3</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts']</td>\n",
       "      <td>0.993173</td>\n",
       "      <td>0.992951</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.945262</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>0.992951</td>\n",
       "      <td>0.908371</td>\n",
       "      <td>2</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.991929</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.997550</td>\n",
       "      <td>0.991929</td>\n",
       "      <td>0.908077</td>\n",
       "      <td>5</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len']</td>\n",
       "      <td>0.994841</td>\n",
       "      <td>0.989840</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.797438</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.989840</td>\n",
       "      <td>0.887198</td>\n",
       "      <td>3</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994732</td>\n",
       "      <td>0.988241</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.772890</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.988241</td>\n",
       "      <td>0.871691</td>\n",
       "      <td>3</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts']</td>\n",
       "      <td>0.992038</td>\n",
       "      <td>0.984194</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.716937</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.984194</td>\n",
       "      <td>0.834755</td>\n",
       "      <td>2</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991759</td>\n",
       "      <td>0.982845</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.700057</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>0.982845</td>\n",
       "      <td>0.823107</td>\n",
       "      <td>2</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.982595</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.996189</td>\n",
       "      <td>0.982595</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>6</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.973371</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.600856</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>0.973371</td>\n",
       "      <td>0.748975</td>\n",
       "      <td>7</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.969879</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.570736</td>\n",
       "      <td>0.993740</td>\n",
       "      <td>0.969879</td>\n",
       "      <td>0.725052</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year']</td>\n",
       "      <td>0.961572</td>\n",
       "      <td>0.960034</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.955672</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.473883</td>\n",
       "      <td>0.990201</td>\n",
       "      <td>0.955672</td>\n",
       "      <td>0.641001</td>\n",
       "      <td>8</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954704</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.468477</td>\n",
       "      <td>0.991018</td>\n",
       "      <td>0.954704</td>\n",
       "      <td>0.636205</td>\n",
       "      <td>10</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.546329</td>\n",
       "      <td>0.739310</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.056403</td>\n",
       "      <td>0.351116</td>\n",
       "      <td>0.739310</td>\n",
       "      <td>0.097193</td>\n",
       "      <td>2</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts']</td>\n",
       "      <td>0.739098</td>\n",
       "      <td>0.739103</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.056356</td>\n",
       "      <td>0.351116</td>\n",
       "      <td>0.739103</td>\n",
       "      <td>0.097124</td>\n",
       "      <td>2</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts']</td>\n",
       "      <td>0.546460</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.056165</td>\n",
       "      <td>0.351116</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>0.096840</td>\n",
       "      <td>2</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len']</td>\n",
       "      <td>0.655808</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.065702</td>\n",
       "      <td>0.574850</td>\n",
       "      <td>0.656311</td>\n",
       "      <td>0.117926</td>\n",
       "      <td>3</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len']</td>\n",
       "      <td>0.615780</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.065804</td>\n",
       "      <td>0.577028</td>\n",
       "      <td>0.655702</td>\n",
       "      <td>0.118135</td>\n",
       "      <td>3</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619299</td>\n",
       "      <td>0.654114</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066418</td>\n",
       "      <td>0.586282</td>\n",
       "      <td>0.654114</td>\n",
       "      <td>0.119319</td>\n",
       "      <td>3</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.621779</td>\n",
       "      <td>0.642887</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>0.592814</td>\n",
       "      <td>0.642887</td>\n",
       "      <td>0.117144</td>\n",
       "      <td>5</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.645126</td>\n",
       "      <td>0.642887</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.064968</td>\n",
       "      <td>0.592542</td>\n",
       "      <td>0.642887</td>\n",
       "      <td>0.117097</td>\n",
       "      <td>5</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.620306</td>\n",
       "      <td>0.642703</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.064961</td>\n",
       "      <td>0.592814</td>\n",
       "      <td>0.642703</td>\n",
       "      <td>0.117090</td>\n",
       "      <td>5</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_id</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631346</td>\n",
       "      <td>0.640603</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066824</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.640603</td>\n",
       "      <td>0.120578</td>\n",
       "      <td>7</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.632179</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066690</td>\n",
       "      <td>0.615133</td>\n",
       "      <td>0.640570</td>\n",
       "      <td>0.120334</td>\n",
       "      <td>7</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.631820</td>\n",
       "      <td>0.640505</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066627</td>\n",
       "      <td>0.614589</td>\n",
       "      <td>0.640505</td>\n",
       "      <td>0.120221</td>\n",
       "      <td>6</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631141</td>\n",
       "      <td>0.640440</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.616494</td>\n",
       "      <td>0.640440</td>\n",
       "      <td>0.120530</td>\n",
       "      <td>6</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.641546</td>\n",
       "      <td>0.639711</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.066459</td>\n",
       "      <td>0.614317</td>\n",
       "      <td>0.639711</td>\n",
       "      <td>0.119942</td>\n",
       "      <td>7</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.641284</td>\n",
       "      <td>0.639483</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.613228</td>\n",
       "      <td>0.639483</td>\n",
       "      <td>0.119688</td>\n",
       "      <td>6</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>quantity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.639102</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066069</td>\n",
       "      <td>0.611323</td>\n",
       "      <td>0.639102</td>\n",
       "      <td>0.119249</td>\n",
       "      <td>4</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.622772</td>\n",
       "      <td>0.638645</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.064888</td>\n",
       "      <td>0.599619</td>\n",
       "      <td>0.638645</td>\n",
       "      <td>0.117103</td>\n",
       "      <td>4</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.640564</td>\n",
       "      <td>0.637840</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.591726</td>\n",
       "      <td>0.637840</td>\n",
       "      <td>0.115512</td>\n",
       "      <td>4</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.639911</td>\n",
       "      <td>0.637818</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.614317</td>\n",
       "      <td>0.637818</td>\n",
       "      <td>0.119390</td>\n",
       "      <td>8</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.631204</td>\n",
       "      <td>0.637764</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.066237</td>\n",
       "      <td>0.615678</td>\n",
       "      <td>0.637764</td>\n",
       "      <td>0.119607</td>\n",
       "      <td>8</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.626800</td>\n",
       "      <td>0.633152</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.064770</td>\n",
       "      <td>0.608601</td>\n",
       "      <td>0.633152</td>\n",
       "      <td>0.117080</td>\n",
       "      <td>8</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.632857</td>\n",
       "      <td>0.631563</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.565324</td>\n",
       "      <td>0.631563</td>\n",
       "      <td>0.109247</td>\n",
       "      <td>10</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.631517</td>\n",
       "      <td>0.629040</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.063243</td>\n",
       "      <td>0.599619</td>\n",
       "      <td>0.629040</td>\n",
       "      <td>0.114418</td>\n",
       "      <td>9</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.619945</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.600435</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.114538</td>\n",
       "      <td>9</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617302</td>\n",
       "      <td>0.627517</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.063165</td>\n",
       "      <td>0.601524</td>\n",
       "      <td>0.627517</td>\n",
       "      <td>0.114324</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>over</td>\n",
       "      <td>['year', 'num_parts', 'set_num_len', 'set_name...</td>\n",
       "      <td>0.606561</td>\n",
       "      <td>0.617901</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.060775</td>\n",
       "      <td>0.592270</td>\n",
       "      <td>0.617901</td>\n",
       "      <td>0.110239</td>\n",
       "      <td>10</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.601497</td>\n",
       "      <td>0.616585</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.060473</td>\n",
       "      <td>0.591181</td>\n",
       "      <td>0.616585</td>\n",
       "      <td>0.109722</td>\n",
       "      <td>10</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>over</td>\n",
       "      <td>['year']</td>\n",
       "      <td>0.731539</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1, random_state=1)</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>0.945291</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>0.139610</td>\n",
       "      <td>1</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.732025</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>0.945291</td>\n",
       "      <td>0.534347</td>\n",
       "      <td>0.139610</td>\n",
       "      <td>1</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>1</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "      <td>set_num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>balanced</td>\n",
       "      <td>['year']</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>LogisticRegression(C=1000, class_weight='balan...</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>1</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>over</td>\n",
       "      <td>['year']</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>1</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "      <td>year</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample                                               desc  train_score  \\\n",
       "0   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999401   \n",
       "1   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999792   \n",
       "0       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999558   \n",
       "1       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999791   \n",
       "2       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999873   \n",
       "2   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999861   \n",
       "3       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999873   \n",
       "13     under                                                NaN     0.999654   \n",
       "3   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999861   \n",
       "4       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999920   \n",
       "4   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999903   \n",
       "5       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999993   \n",
       "6       over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999920   \n",
       "5   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999903   \n",
       "6   balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.999984   \n",
       "7   balanced               ['year', 'num_parts', 'set_num_len']     0.994464   \n",
       "8   balanced                              ['year', 'num_parts']     0.993173   \n",
       "14     under                                                NaN     0.999906   \n",
       "7       over               ['year', 'num_parts', 'set_num_len']     0.994841   \n",
       "12     under                                                NaN     0.994732   \n",
       "8       over                              ['year', 'num_parts']     0.992038   \n",
       "11     under                                                NaN     0.991759   \n",
       "15     under                                                NaN     0.999953   \n",
       "16     under                                                NaN     0.999953   \n",
       "18     under                                                NaN     0.999969   \n",
       "9   balanced                                           ['year']     0.961572   \n",
       "17     under                                                NaN     0.999969   \n",
       "19     under                                                NaN     1.000000   \n",
       "1      under                                                NaN     0.546329   \n",
       "10  balanced                              ['year', 'num_parts']     0.739098   \n",
       "9       over                              ['year', 'num_parts']     0.546460   \n",
       "11  balanced               ['year', 'num_parts', 'set_num_len']     0.655808   \n",
       "10      over               ['year', 'num_parts', 'set_num_len']     0.615780   \n",
       "2      under                                                NaN     0.619299   \n",
       "11      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.621779   \n",
       "12  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.645126   \n",
       "4      under                                                NaN     0.620306   \n",
       "6      under                                                NaN     0.631346   \n",
       "12      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.632179   \n",
       "13      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.631820   \n",
       "5      under                                                NaN     0.631141   \n",
       "13  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.641546   \n",
       "14  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.641284   \n",
       "3      under                                                NaN     0.626235   \n",
       "14      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.622772   \n",
       "15  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.640564   \n",
       "16  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.639911   \n",
       "7      under                                                NaN     0.631204   \n",
       "15      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.626800   \n",
       "17  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.632857   \n",
       "18  balanced  ['year', 'num_parts', 'set_num_len', 'set_name...     0.631517   \n",
       "16      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.619945   \n",
       "8      under                                                NaN     0.617302   \n",
       "17      over  ['year', 'num_parts', 'set_num_len', 'set_name...     0.606561   \n",
       "9      under                                                NaN     0.601497   \n",
       "18      over                                           ['year']     0.731539   \n",
       "10     under                                                NaN     0.732025   \n",
       "0      under                                                NaN     0.500000   \n",
       "19  balanced                                           ['year']     0.038428   \n",
       "19      over                                           ['year']     0.500000   \n",
       "\n",
       "    test_score                                              model  precision  \\\n",
       "0     0.999347  RandomForestClassifier(n_jobs=-1, random_state=1)   0.992639   \n",
       "1     0.999162  RandomForestClassifier(n_jobs=-1, random_state=1)   0.993687   \n",
       "0     0.999064  RandomForestClassifier(n_jobs=-1, random_state=1)   0.977636   \n",
       "1     0.998956  RandomForestClassifier(n_jobs=-1, random_state=1)   0.985350   \n",
       "2     0.998521  RandomForestClassifier(n_jobs=-1, random_state=1)   0.986791   \n",
       "2     0.998325  RandomForestClassifier(n_jobs=-1, random_state=1)   0.992997   \n",
       "3     0.997944  RandomForestClassifier(n_jobs=-1, random_state=1)   0.984431   \n",
       "13    0.997552  (DecisionTreeClassifier(max_features='auto', r...   0.942747   \n",
       "3     0.997520  RandomForestClassifier(n_jobs=-1, random_state=1)   0.993414   \n",
       "4     0.997378  RandomForestClassifier(n_jobs=-1, random_state=1)   0.981757   \n",
       "4     0.996845  RandomForestClassifier(n_jobs=-1, random_state=1)   0.990435   \n",
       "5     0.996367  RandomForestClassifier(n_jobs=-1, random_state=1)   0.985748   \n",
       "6     0.996008  RandomForestClassifier(n_jobs=-1, random_state=1)   0.971755   \n",
       "5     0.995203  RandomForestClassifier(n_jobs=-1, random_state=1)   0.987338   \n",
       "6     0.994757  RandomForestClassifier(n_jobs=-1, random_state=1)   0.994424   \n",
       "7     0.994082  RandomForestClassifier(n_jobs=-1, random_state=1)   0.951790   \n",
       "8     0.992951  RandomForestClassifier(n_jobs=-1, random_state=1)   0.945262   \n",
       "14    0.991929  (DecisionTreeClassifier(max_features='auto', r...   0.833333   \n",
       "7     0.989840  RandomForestClassifier(n_jobs=-1, random_state=1)   0.797438   \n",
       "12    0.988241  (DecisionTreeClassifier(max_features='auto', r...   0.772890   \n",
       "8     0.984194  RandomForestClassifier(n_jobs=-1, random_state=1)   0.716937   \n",
       "11    0.982845  (DecisionTreeClassifier(max_features='auto', r...   0.700057   \n",
       "15    0.982595  (DecisionTreeClassifier(max_features='auto', r...   0.697674   \n",
       "16    0.973371  (DecisionTreeClassifier(max_features='auto', r...   0.600856   \n",
       "18    0.969879  (DecisionTreeClassifier(max_features='auto', r...   0.570736   \n",
       "9     0.960034  RandomForestClassifier(n_jobs=-1, random_state=1)   0.000000   \n",
       "17    0.955672  (DecisionTreeClassifier(max_features='auto', r...   0.473883   \n",
       "19    0.954704  (DecisionTreeClassifier(max_features='auto', r...   0.468477   \n",
       "1     0.739310                               LogisticRegression()   0.056403   \n",
       "10    0.739103  LogisticRegression(C=1000, class_weight='balan...   0.056356   \n",
       "9     0.738255                               LogisticRegression()   0.056165   \n",
       "11    0.656311  LogisticRegression(C=1000, class_weight='balan...   0.065702   \n",
       "10    0.655702                               LogisticRegression()   0.065804   \n",
       "2     0.654114                               LogisticRegression()   0.066418   \n",
       "11    0.642887                               LogisticRegression()   0.064994   \n",
       "12    0.642887  LogisticRegression(C=1000, class_weight='balan...   0.064968   \n",
       "4     0.642703                               LogisticRegression()   0.064961   \n",
       "6     0.640603                               LogisticRegression()   0.066824   \n",
       "12    0.640570                               LogisticRegression()   0.066690   \n",
       "13    0.640505                               LogisticRegression()   0.066627   \n",
       "5     0.640440                               LogisticRegression()   0.066794   \n",
       "13    0.639711  LogisticRegression(C=1000, class_weight='balan...   0.066459   \n",
       "14    0.639483  LogisticRegression(C=1000, class_weight='balan...   0.066315   \n",
       "3     0.639102                               LogisticRegression()   0.066069   \n",
       "14    0.638645                               LogisticRegression()   0.064888   \n",
       "15    0.637840  LogisticRegression(C=1000, class_weight='balan...   0.064003   \n",
       "16    0.637818  LogisticRegression(C=1000, class_weight='balan...   0.066120   \n",
       "7     0.637764                               LogisticRegression()   0.066237   \n",
       "15    0.633152                               LogisticRegression()   0.064770   \n",
       "17    0.631563  LogisticRegression(C=1000, class_weight='balan...   0.060466   \n",
       "18    0.629040  LogisticRegression(C=1000, class_weight='balan...   0.063243   \n",
       "16    0.628975                               LogisticRegression()   0.063307   \n",
       "8     0.627517                               LogisticRegression()   0.063165   \n",
       "17    0.617901                               LogisticRegression()   0.060775   \n",
       "9     0.616585                               LogisticRegression()   0.060473   \n",
       "18    0.534347  RandomForestClassifier(n_jobs=-1, random_state=1)   0.075371   \n",
       "10    0.534347  (DecisionTreeClassifier(max_features='auto', r...   0.075371   \n",
       "0     0.039966                               LogisticRegression()   0.039966   \n",
       "19    0.039966  LogisticRegression(C=1000, class_weight='balan...   0.039966   \n",
       "19    0.039966                               LogisticRegression()   0.039966   \n",
       "\n",
       "      recall  accuracy  f1_score  num_features  num_rows_train  num_rows_test  \\\n",
       "0   0.991018  0.999347  0.991828             4          827359          91929   \n",
       "1   0.985302  0.999162  0.989477             5          827359          91929   \n",
       "0   0.999456  0.999064  0.988425             4         1591130          91929   \n",
       "1   0.988568  0.998956  0.986957             5         1591130          91929   \n",
       "2   0.976048  0.998521  0.981390             6         1591130          91929   \n",
       "2   0.964888  0.998325  0.978741             6          827359          91929   \n",
       "3   0.963800  0.997944  0.974006             7         1591130          91929   \n",
       "13  0.999456  0.997552  0.970273             4           63588          91929   \n",
       "3   0.944203  0.997520  0.968183             7          827359          91929   \n",
       "4   0.952096  0.997378  0.966699             9         1591130          91929   \n",
       "4   0.930049  0.996845  0.959293             9          827359          91929   \n",
       "5   0.922428  0.996367  0.953037            10         1591130          91929   \n",
       "6   0.927055  0.996008  0.948879             8         1591130          91929   \n",
       "5   0.891399  0.995203  0.936919             8          827359          91929   \n",
       "6   0.873707  0.994757  0.930165            10          827359          91929   \n",
       "7   0.897387  0.994082  0.923788             3          827359          91929   \n",
       "8   0.874251  0.992951  0.908371             2          827359          91929   \n",
       "14  0.997550  0.991929  0.908077             5           63588          91929   \n",
       "7   0.999728  0.989840  0.887198             3         1591130          91929   \n",
       "12  0.999456  0.988241  0.871691             3           63588          91929   \n",
       "8   0.998911  0.984194  0.834755             2         1591130          91929   \n",
       "11  0.998639  0.982845  0.823107             2           63588          91929   \n",
       "15  0.996189  0.982595  0.820628             6           63588          91929   \n",
       "16  0.994012  0.973371  0.748975             7           63588          91929   \n",
       "18  0.993740  0.969879  0.725052             9           63588          91929   \n",
       "9   0.000000  0.960034  0.000000             1          827359          91929   \n",
       "17  0.990201  0.955672  0.641001             8           63588          91929   \n",
       "19  0.991018  0.954704  0.636205            10           63588          91929   \n",
       "1   0.351116  0.739310  0.097193             2           63588          91929   \n",
       "10  0.351116  0.739103  0.097124             2          827359          91929   \n",
       "9   0.351116  0.738255  0.096840             2         1591130          91929   \n",
       "11  0.574850  0.656311  0.117926             3          827359          91929   \n",
       "10  0.577028  0.655702  0.118135             3         1591130          91929   \n",
       "2   0.586282  0.654114  0.119319             3           63588          91929   \n",
       "11  0.592814  0.642887  0.117144             5         1591130          91929   \n",
       "12  0.592542  0.642887  0.117097             5          827359          91929   \n",
       "4   0.592814  0.642703  0.117090             5           63588          91929   \n",
       "6   0.616494  0.640603  0.120578             7           63588          91929   \n",
       "12  0.615133  0.640570  0.120334             7         1591130          91929   \n",
       "13  0.614589  0.640505  0.120221             6         1591130          91929   \n",
       "5   0.616494  0.640440  0.120530             6           63588          91929   \n",
       "13  0.614317  0.639711  0.119942             7          827359          91929   \n",
       "14  0.613228  0.639483  0.119688             6          827359          91929   \n",
       "3   0.611323  0.639102  0.119249             4           63588          91929   \n",
       "14  0.599619  0.638645  0.117103             4         1591130          91929   \n",
       "15  0.591726  0.637840  0.115512             4          827359          91929   \n",
       "16  0.614317  0.637818  0.119390             8          827359          91929   \n",
       "7   0.615678  0.637764  0.119607             8           63588          91929   \n",
       "15  0.608601  0.633152  0.117080             8         1591130          91929   \n",
       "17  0.565324  0.631563  0.109247            10          827359          91929   \n",
       "18  0.599619  0.629040  0.114418             9          827359          91929   \n",
       "16  0.600435  0.628975  0.114538             9         1591130          91929   \n",
       "8   0.601524  0.627517  0.114324             9           63588          91929   \n",
       "17  0.592270  0.617901  0.110239            10         1591130          91929   \n",
       "9   0.591181  0.616585  0.109722            10           63588          91929   \n",
       "18  0.945291  0.534347  0.139610             1         1591130          91929   \n",
       "10  0.945291  0.534347  0.139610             1           63588          91929   \n",
       "0   1.000000  0.039966  0.076860             1           63588          91929   \n",
       "19  1.000000  0.039966  0.076860             1          827359          91929   \n",
       "19  1.000000  0.039966  0.076860             1         1591130          91929   \n",
       "\n",
       "      last_feature missing_feature  \n",
       "0     set_name_len             NaN  \n",
       "1         color_id             NaN  \n",
       "0     set_name_len             NaN  \n",
       "1         color_id             NaN  \n",
       "2         quantity             NaN  \n",
       "2         quantity             NaN  \n",
       "3         is_trans             NaN  \n",
       "13    set_name_len         set_num  \n",
       "3         is_trans             NaN  \n",
       "4   color_name_len             NaN  \n",
       "4   color_name_len             NaN  \n",
       "5    part_name_len             NaN  \n",
       "6     part_num_len             NaN  \n",
       "5     part_num_len             NaN  \n",
       "6    part_name_len             NaN  \n",
       "7      set_num_len             NaN  \n",
       "8        num_parts             NaN  \n",
       "14        color_id         set_num  \n",
       "7      set_num_len             NaN  \n",
       "12     set_num_len         set_num  \n",
       "8        num_parts             NaN  \n",
       "11       num_parts         set_num  \n",
       "15        quantity         set_num  \n",
       "16        is_trans         set_num  \n",
       "18  color_name_len         set_num  \n",
       "9             year             NaN  \n",
       "17    part_num_len         set_num  \n",
       "19   part_name_len         set_num  \n",
       "1        num_parts         set_num  \n",
       "10       num_parts             NaN  \n",
       "9        num_parts             NaN  \n",
       "11     set_num_len             NaN  \n",
       "10     set_num_len             NaN  \n",
       "2      set_num_len         set_num  \n",
       "11        color_id             NaN  \n",
       "12        color_id             NaN  \n",
       "4         color_id         set_num  \n",
       "6         is_trans         set_num  \n",
       "12        is_trans             NaN  \n",
       "13        quantity             NaN  \n",
       "5         quantity         set_num  \n",
       "13        is_trans             NaN  \n",
       "14        quantity             NaN  \n",
       "3     set_name_len         set_num  \n",
       "14    set_name_len             NaN  \n",
       "15    set_name_len             NaN  \n",
       "16    part_num_len             NaN  \n",
       "7     part_num_len         set_num  \n",
       "15    part_num_len             NaN  \n",
       "17   part_name_len             NaN  \n",
       "18  color_name_len             NaN  \n",
       "16  color_name_len             NaN  \n",
       "8   color_name_len         set_num  \n",
       "17   part_name_len             NaN  \n",
       "9    part_name_len         set_num  \n",
       "18            year             NaN  \n",
       "10            year         set_num  \n",
       "0             year         set_num  \n",
       "19            year             NaN  \n",
       "19            year             NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_table = hyper_table.sort_values('test_score', ascending=False)\n",
    "hyper_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb1fe7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_dfg_under.to_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/ht_dfg_under.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4818c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_table.to_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/hyper_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4f61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0357a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_table = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "300bb1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'is_trans set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6841e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=1, random_state = 1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c361c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_0 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_0,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d553d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'part_num_len set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "271285ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_1 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_1,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b06bc51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'set_num_len set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9643e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_2 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_2,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0],\n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4239ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'color_name_len set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0fea9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_3 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_3,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0],\n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aab8e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'quantity set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1299ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_4 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_4,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4d179f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'color_id set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcbb7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_5 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_5,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d2f88c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'part_name_len set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89cc2e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_6 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_6,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a421051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'year set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b76c5cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_7 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_7,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "952efe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'set_name_len set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb24b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_8 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_8,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0], \n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da9f077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'num_parts set_num set_name theme_id theme_name id part_num color_name part_name theme_name_len is_ninjago'.split()\n",
    "\n",
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(df.columns):\n",
    "    if i > 100:\n",
    "        break\n",
    "    if name in target_names:\n",
    "        continue\n",
    "    fn.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfd856fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true=df_test['is_ninjago'], y_pred=y_pred)\n",
    "\n",
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1_9 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    missing_feature=target_names[0], \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1_9,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0],\n",
    "                    last_feature=fn[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "012253fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>missing_feature</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows_train</th>\n",
       "      <th>num_rows_test</th>\n",
       "      <th>last_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>under</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.939312</td>\n",
       "      <td>0.394014</td>\n",
       "      <td>0.963800</td>\n",
       "      <td>0.939312</td>\n",
       "      <td>0.559356</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>under</td>\n",
       "      <td>quantity</td>\n",
       "      <td>0.980515</td>\n",
       "      <td>0.932905</td>\n",
       "      <td>0.369040</td>\n",
       "      <td>0.956451</td>\n",
       "      <td>0.932905</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under</td>\n",
       "      <td>color_id</td>\n",
       "      <td>0.978911</td>\n",
       "      <td>0.932252</td>\n",
       "      <td>0.366590</td>\n",
       "      <td>0.955090</td>\n",
       "      <td>0.932252</td>\n",
       "      <td>0.529820</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>under</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>0.978675</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.345350</td>\n",
       "      <td>0.962167</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.508267</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>0.968846</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>0.274144</td>\n",
       "      <td>0.928688</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>0.423325</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>under</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>0.967195</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.259729</td>\n",
       "      <td>0.930049</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.406061</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>0.964018</td>\n",
       "      <td>0.888599</td>\n",
       "      <td>0.253657</td>\n",
       "      <td>0.920250</td>\n",
       "      <td>0.888599</td>\n",
       "      <td>0.397695</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>under</td>\n",
       "      <td>year</td>\n",
       "      <td>0.944565</td>\n",
       "      <td>0.834611</td>\n",
       "      <td>0.177825</td>\n",
       "      <td>0.866086</td>\n",
       "      <td>0.834611</td>\n",
       "      <td>0.295067</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>under</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>0.818980</td>\n",
       "      <td>0.162616</td>\n",
       "      <td>0.850572</td>\n",
       "      <td>0.818980</td>\n",
       "      <td>0.273033</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>under</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>0.925929</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>0.147912</td>\n",
       "      <td>0.813555</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>0.250314</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample missing_feature  train_score  test_score  precision    recall  \\\n",
       "3  under  color_name_len     0.981600    0.939312   0.394014  0.963800   \n",
       "4  under        quantity     0.980515    0.932905   0.369040  0.956451   \n",
       "5  under        color_id     0.978911    0.932252   0.366590  0.955090   \n",
       "6  under   part_name_len     0.978675    0.925595   0.345350  0.962167   \n",
       "2  under     set_num_len     0.968846    0.898878   0.274144  0.928688   \n",
       "1  under    part_num_len     0.967195    0.891264   0.259729  0.930049   \n",
       "0  under        is_trans     0.964018    0.888599   0.253657  0.920250   \n",
       "7  under            year     0.944565    0.834611   0.177825  0.866086   \n",
       "8  under    set_name_len     0.939800    0.818980   0.162616  0.850572   \n",
       "9  under       num_parts     0.925929    0.805241   0.147912  0.813555   \n",
       "\n",
       "   accuracy  f1_score                                              model  \\\n",
       "3  0.939312  0.559356  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "4  0.932905  0.532586  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "5  0.932252  0.529820  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "6  0.925595  0.508267  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "2  0.898878  0.423325  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "1  0.891264  0.406061  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "0  0.888599  0.397695  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "7  0.834611  0.295067  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "8  0.818980  0.273033  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "9  0.805241  0.250314  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "\n",
       "   num_features  num_rows_train  num_rows_test    last_feature  \n",
       "3             9           63588          91929   part_name_len  \n",
       "4             9           63588          91929   part_name_len  \n",
       "5             9           63588          91929   part_name_len  \n",
       "6             9           63588          91929  color_name_len  \n",
       "2             9           63588          91929   part_name_len  \n",
       "1             9           63588          91929   part_name_len  \n",
       "0             9           63588          91929   part_name_len  \n",
       "7             9           63588          91929   part_name_len  \n",
       "8             9           63588          91929   part_name_len  \n",
       "9             9           63588          91929   part_name_len  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = pd.DataFrame(hyper_table).sort_values('test_score', ascending=False)\n",
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63bc357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht['diff'] = ht['test_score'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7eab849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>missing_feature</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows_train</th>\n",
       "      <th>num_rows_test</th>\n",
       "      <th>last_feature</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>under</td>\n",
       "      <td>year</td>\n",
       "      <td>0.944565</td>\n",
       "      <td>0.834611</td>\n",
       "      <td>0.177825</td>\n",
       "      <td>0.866086</td>\n",
       "      <td>0.834611</td>\n",
       "      <td>0.295067</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.053987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>under</td>\n",
       "      <td>set_num_len</td>\n",
       "      <td>0.968846</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>0.274144</td>\n",
       "      <td>0.928688</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>0.423325</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.026716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>under</td>\n",
       "      <td>set_name_len</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>0.818980</td>\n",
       "      <td>0.162616</td>\n",
       "      <td>0.850572</td>\n",
       "      <td>0.818980</td>\n",
       "      <td>0.273033</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.015632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>under</td>\n",
       "      <td>num_parts</td>\n",
       "      <td>0.925929</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>0.147912</td>\n",
       "      <td>0.813555</td>\n",
       "      <td>0.805241</td>\n",
       "      <td>0.250314</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.013739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>under</td>\n",
       "      <td>part_num_len</td>\n",
       "      <td>0.967195</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.259729</td>\n",
       "      <td>0.930049</td>\n",
       "      <td>0.891264</td>\n",
       "      <td>0.406061</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>under</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>0.978675</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.345350</td>\n",
       "      <td>0.962167</td>\n",
       "      <td>0.925595</td>\n",
       "      <td>0.508267</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>-0.006657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>under</td>\n",
       "      <td>quantity</td>\n",
       "      <td>0.980515</td>\n",
       "      <td>0.932905</td>\n",
       "      <td>0.369040</td>\n",
       "      <td>0.956451</td>\n",
       "      <td>0.932905</td>\n",
       "      <td>0.532586</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>is_trans</td>\n",
       "      <td>0.964018</td>\n",
       "      <td>0.888599</td>\n",
       "      <td>0.253657</td>\n",
       "      <td>0.920250</td>\n",
       "      <td>0.888599</td>\n",
       "      <td>0.397695</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.002665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>under</td>\n",
       "      <td>color_id</td>\n",
       "      <td>0.978911</td>\n",
       "      <td>0.932252</td>\n",
       "      <td>0.366590</td>\n",
       "      <td>0.955090</td>\n",
       "      <td>0.932252</td>\n",
       "      <td>0.529820</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>-0.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>under</td>\n",
       "      <td>color_name_len</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>0.939312</td>\n",
       "      <td>0.394014</td>\n",
       "      <td>0.963800</td>\n",
       "      <td>0.939312</td>\n",
       "      <td>0.559356</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>9</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "      <td>part_name_len</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample missing_feature  train_score  test_score  precision    recall  \\\n",
       "7  under            year     0.944565    0.834611   0.177825  0.866086   \n",
       "2  under     set_num_len     0.968846    0.898878   0.274144  0.928688   \n",
       "8  under    set_name_len     0.939800    0.818980   0.162616  0.850572   \n",
       "9  under       num_parts     0.925929    0.805241   0.147912  0.813555   \n",
       "1  under    part_num_len     0.967195    0.891264   0.259729  0.930049   \n",
       "6  under   part_name_len     0.978675    0.925595   0.345350  0.962167   \n",
       "4  under        quantity     0.980515    0.932905   0.369040  0.956451   \n",
       "0  under        is_trans     0.964018    0.888599   0.253657  0.920250   \n",
       "5  under        color_id     0.978911    0.932252   0.366590  0.955090   \n",
       "3  under  color_name_len     0.981600    0.939312   0.394014  0.963800   \n",
       "\n",
       "   accuracy  f1_score                                              model  \\\n",
       "7  0.834611  0.295067  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "2  0.898878  0.423325  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "8  0.818980  0.273033  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "9  0.805241  0.250314  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "1  0.891264  0.406061  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "6  0.925595  0.508267  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "4  0.932905  0.532586  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "0  0.888599  0.397695  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "5  0.932252  0.529820  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "3  0.939312  0.559356  (DecisionTreeClassifier(max_features='auto', r...   \n",
       "\n",
       "   num_features  num_rows_train  num_rows_test    last_feature      diff  \n",
       "7             9           63588          91929   part_name_len -0.053987  \n",
       "2             9           63588          91929   part_name_len -0.026716  \n",
       "8             9           63588          91929   part_name_len -0.015632  \n",
       "9             9           63588          91929   part_name_len -0.013739  \n",
       "1             9           63588          91929   part_name_len -0.007615  \n",
       "6             9           63588          91929  color_name_len -0.006657  \n",
       "4             9           63588          91929   part_name_len -0.006407  \n",
       "0             9           63588          91929   part_name_len -0.002665  \n",
       "5             9           63588          91929   part_name_len -0.000653  \n",
       "3             9           63588          91929   part_name_len       NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.sort_values('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9da45f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_table = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc5dc7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['set_num', 'set_name', 'year', 'theme_id', 'num_parts', 'set_num_len',\n",
       "       'set_name_len', 'theme_name', 'id', 'part_num', 'color_id', 'quantity',\n",
       "       'color_name', 'part_name', 'is_trans', 'theme_name_len', 'part_num_len',\n",
       "       'color_name_len', 'part_name_len', 'is_ninjago'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee793774",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = 'year num_parts set_name_len'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "792786a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'num_parts', 'set_name_len']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = list()\n",
    "\n",
    "for i, name in enumerate(target_names):\n",
    "    fn.append(name)\n",
    "    \n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e5176aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "\n",
    "s_train = model_rf.score(df_balancedbyunder[fn], df_balancedbyunder['is_ninjago'])\n",
    "s_test = model_rf.score(df_test[fn], df_test['is_ninjago'])\n",
    "y_pred = model_rf.predict(df_test[fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a66a2fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3d85b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(df_test['is_ninjago'], y_pred)\n",
    "recall = recall_score(df_test['is_ninjago'], y_pred)\n",
    "accuracy = accuracy_score(df_test['is_ninjago'], y_pred)\n",
    "f1 = f1_score(df_test['is_ninjago'], y_pred)\n",
    "\n",
    "hyper_table.append(dict(sample='under', \n",
    "                    train_score=s_train, \n",
    "                    test_score=s_test,\n",
    "                    precision=precision,\n",
    "                    recall=recall,\n",
    "                    accuracy=accuracy,\n",
    "                    f1_score=f1,\n",
    "                    model=model_rf, \n",
    "                    num_features=df[fn].shape[1], \n",
    "                    num_rows_train=df_balancedbyunder.shape[0], \n",
    "                    num_rows_test=df_test.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e3d9990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows_train</th>\n",
       "      <th>num_rows_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>0.998396</td>\n",
       "      <td>0.993343</td>\n",
       "      <td>0.857878</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.993343</td>\n",
       "      <td>0.923038</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>3</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample  train_score  test_score  precision    recall  accuracy  f1_score  \\\n",
       "0  under     0.998396    0.993343   0.857878  0.998911  0.993343  0.923038   \n",
       "\n",
       "                                               model  num_features  \\\n",
       "0  (DecisionTreeClassifier(max_features='auto', r...             3   \n",
       "\n",
       "   num_rows_train  num_rows_test  \n",
       "0           63588          91929  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_fr_under = pd.DataFrame(hyper_table)\n",
    "ht_fr_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "243cdc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_fr_under.to_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/ht_fr_under.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30cfe96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_fr_bal = pd.read_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/ht_fr_bal.csv')\n",
    "ht_fr_over = pd.read_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/ht_fr_over.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1587a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_table = pd.concat([ht_fr_bal, ht_fr_over, ht_fr_under])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "00d0b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>num_rows_train</th>\n",
       "      <th>num_rows_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balanced</td>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.998367</td>\n",
       "      <td>0.998716</td>\n",
       "      <td>0.984170</td>\n",
       "      <td>RandomForestClassifier(class_weight='balanced'...</td>\n",
       "      <td>3</td>\n",
       "      <td>827359</td>\n",
       "      <td>91929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>over</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.998618</td>\n",
       "      <td>0.967079</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.998618</td>\n",
       "      <td>0.983001</td>\n",
       "      <td>RandomForestClassifier(n_estimators=1, n_jobs=...</td>\n",
       "      <td>3</td>\n",
       "      <td>1591130</td>\n",
       "      <td>91929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under</td>\n",
       "      <td>0.998396</td>\n",
       "      <td>0.993343</td>\n",
       "      <td>0.857878</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.993343</td>\n",
       "      <td>0.923038</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "      <td>3</td>\n",
       "      <td>63588</td>\n",
       "      <td>91929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample  train_score  test_score  precision    recall  accuracy  f1_score  \\\n",
       "0  balanced     0.998901    0.998716   0.970370  0.998367  0.998716  0.984170   \n",
       "0      over     0.999403    0.998618   0.967079  0.999456  0.998618  0.983001   \n",
       "0     under     0.998396    0.993343   0.857878  0.998911  0.993343  0.923038   \n",
       "\n",
       "                                               model  num_features  \\\n",
       "0  RandomForestClassifier(class_weight='balanced'...             3   \n",
       "0  RandomForestClassifier(n_estimators=1, n_jobs=...             3   \n",
       "0  (DecisionTreeClassifier(max_features='auto', r...             3   \n",
       "\n",
       "   num_rows_train  num_rows_test  \n",
       "0          827359          91929  \n",
       "0         1591130          91929  \n",
       "0           63588          91929  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_table = hyper_table.sort_values('test_score', ascending=False)\n",
    "hyper_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45587e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_table.to_csv('C:/Users/marki/Desktop/SB Data Science BC/Springboard/Capstone2/data from notebooks/hyper_table_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c2bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
